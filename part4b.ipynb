{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6534fd1-a204-492b-8aa4-b7254d6054be",
   "metadata": {},
   "source": [
    "# Part 4b: A gist of other synthesis methods\n",
    "\n",
    "(Draft: May move around topics or expand on some)\n",
    "\n",
    "## Subtractive synthesis\n",
    "\n",
    "In some way the oppposite of additive synthesis, the technique is about applying filters to an existing \"spectrally rich\" signal -- filters which selectively attentuate (meaning cut out) some specific frequencies in order to manipulate the tonal quality. We will not cover subtractive synthesis in detail.\n",
    "\n",
    "## Physical modeling synthesis\n",
    "\n",
    "In the above discussion, we applied an exponentially decaying amplitude shape to a sine wave and got a fairly relatable sound. We also noted that such a decaying tone is the common mode of vibration of metalling objects. Physical modeling asks the following question -- instead of trying to mimic the patterns that we observe, what if we directly derive the sound signal from a model of the physics of the process we intend to mimic?\n",
    "\n",
    "For example, a \"damped harmonic oscillator\" can be described by the following equation -\n",
    "\n",
    "$$ \\frac{d^2x}{dt^2} + \\alpha\\frac{dx}{dt} + \\beta x = f(t) $$\n",
    "\n",
    "where $f(t)$ is a force driving the oscillator. (If we want to consider the behaviour of the oscillator that is not driven by a force, we can set $f(t) = 0$.)\n",
    "\n",
    "To get a decaying exponential kind of pattern, we can solve this equation in incremental time steps. This is especially attractive because we can apply an $f(t)$ of our choice and influence the behaviour of the oscillator ... something which we may not be able to mimic by constructing shaping functions on our own.\n",
    "\n",
    "The way to solve such an equation is to realize that the \"state\" of such an oscillator is described by two quantities at any given point in time - $x(t)$ and $x'(t) = \\frac{dx(t)}{dt}$. If we know the two values at one instant $t_k$, we can calculate their values at a short while after -- $t_k + \\delta t$ -- using the following update equations --\n",
    "\n",
    "$$ x(t_k+\\delta t) = x(t_k) + x'(t_k) \\delta t $$\n",
    "$$ x'(t_k + \\delta t) = x'(t_k) + x''(t_k) \\delta t $$\n",
    "where\n",
    "$$ x''(t_k) = f(t_k) - \\alpha x'(t_k) - \\beta x(t_k) $$\n",
    "as per the dynamical equation of the oscillator. Notice how all we're doing is using an approximation of the limit definition of the derivative of a function -\n",
    "\n",
    "$$f'(t) = \\frac{df(t)}{dt} = \\lim_{\\delta t -> 0}{\\frac{f(t + \\delta t) - f(t)}{\\delta t}}$$\n",
    "\n",
    "So if we choose a sufficiently small $\\delta t$, we can then say -\n",
    "\n",
    "$$f'(t) = \\frac{df(t)}{dt} \\approx \\frac{f(t + \\delta t) - f(t)}{\\delta t}$$\n",
    "\n",
    "and therefore\n",
    "\n",
    "$$f(t + \\delta t) \\approx f(t) + f'(t)\\delta t$$\n",
    "\n",
    "The above expression is the [Taylor expansion][tseries] of the function $f(t)$ up to the first derivative. If we expand it to the second derivative, we get -\n",
    "\n",
    "$$f(t + \\delta t) \\approx f(t) + f'(t) \\delta t + (1/2)f''(t){\\delta t}^2$$\n",
    "\n",
    "If we use this better approximation, we can then write -\n",
    "\n",
    "$$ x(t_k+\\delta t) = x(t_k) + x'(t_k) \\delta t + (1/2)x''(t_k){\\delta t}^2$$\n",
    "$$ x'(t_k + \\delta t) = x'(t_k) + x''(t_k) \\delta t + (1/2)x'''(t_k){\\delta t}^2 $$\n",
    "$$ x''(t_k) = f(t_k) - \\alpha x'(t_k) - \\beta x(t_k) $$\n",
    "$$x'''(t_k) = f'(t_k) - \\alpha x''(t_k) - \\beta x'(t_k)$$\n",
    "\n",
    "These equations require more quantities such as $f'(t_k)$ to be calculated, but it affords us to use slightly larger values for $\\delta t$ to generate the signal. For our purposes, we'll stick to the first order Taylor expansion for simplicity and use a sufficiently small $\\delta t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89425596-578c-4033-8545-247f053f4f3d",
   "metadata": {},
   "source": [
    "## An aside on Taylor expansion of a differentiable function\n",
    "\n",
    "The full infinite series Taylor expansion is given by -\n",
    "\n",
    "$$f(t+\\delta t) = \\sum_{n=0}^{\\infty}{\\frac{1}{n!}{f^{(n)}(t){\\delta t}^n}}$$\n",
    "\n",
    "where we write the n-th derivative of $f(t)$ as $f^{(n)}(t)$ and $n!$ is the factorial of n, with $0! = 1$. We see how as the value of $n$ gets larger, the value of $\\delta t^n$ gets exponentially smaller and therefore we can stop expanding the series when $\\delta t^n$ has become small enough that we can ignore the n-th term and beyond. \n",
    "\n",
    "When using the Taylor expansion in numerically solving a differential equation, we need to therefore choose a sufficiently small $\\delta t$ and a sufficient number of terms for the precision we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192baa2-7881-43e7-94ca-4267c29c3fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
